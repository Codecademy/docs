---
Title: 'PySpark'
Description: 'A Python API for Apache Spark, consisting of several modules.'
Subjects:
  - 'Computer Science'
  - 'Data Science'
Tags:
  - 'Libraries'
  - 'Modules'
  - 'Deep Learning'
  - 'AI'
  - 'APIs'
  - 'Data Structures'
CatalogContent:
  - 'learn-python-3'
  - 'big-data-pyspark'
---

**PySpark** is a Python [API](https://www.codecademy.com/resources/docs/general/api) for Apache Spark (or Spark), consisting of several modules. Spark is an analytical engine for large-scale distributed data processing and [machine learning](https://www.codecademy.com/resources/docs/ai/machine-learning). Spark applications can run operations with very large datasets on distributed clusters about 100 times faster than traditional Python applications. PySpark has seen wide usage in the [data science](https://www.codecademy.com/resources/docs/general/data-science) and machine learning communities due to the extensive number of data science libraries available in Python, and its ability to efficiently process large datasets.

## Features

Some of the primary features of PySpark include:

- Distributed processing.
- Support of many cluster managers.
- Support of ANSI SQL.
- In-memory computation.

## Installation

Installation requires Java 8 or later. Details on installation can be found on the [Apache Spark website](https://spark.apache.org/docs/latest/api/python/getting_started/install.html).
